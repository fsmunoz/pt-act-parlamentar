{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise da actividade parlamentar das XIV Legislatura: Dezembro de 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduzir cenas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodologia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos dados disponibilizados pela Assembleia da República em formato XML [DadosAbertos] são criadas _dataframes_ (tabelas de duas dimensões) com base na selecção de informação relativa aos padrões de votação de cada partido (e/ou deputados não-inscritos).\n",
    "\n",
    "São fundamentalmente feitas as seguintes análises:\n",
    "\n",
    "1. Vista geral das votações de cada partido, visualizado através de um _heatmap_\n",
    "2. Matriz de distância entre todos os partidos e dendograma\n",
    "3. Identificação de grupos (_spectral clustering_) e visualização das distâncias num espaço cartesiano (_multidimensional scaling_)\n",
    "\n",
    "\n",
    "O tratamento prévio dos dados em formato XML é feito de forma a seleccionar as votações de cada partido (ou deputado não inscrito); este processo tem alguma complexidade que se prende com o próprio processo de votação parlamentar, com múltiplas sessões e votações, pelo que foram \n",
    "\n",
    "De forma acessória são também feitas algumas análises adicionais, já mais removidas do objectivo central de determinação do distânciamento mas que complementam o quadro geral do que é possível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XIII Legislatura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenção e tratamento dos dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --user -q itables matplotlib pandas bs4 html5lib lxml seaborn sklearn pixiedust\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from itables import show\n",
    "import itables.options as opt\n",
    "\n",
    "opt.maxColumns=100\n",
    "opt.maxRows=2000\n",
    "opt.lengthMenu = [10, 20, 50, 100, 200, 500]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenção do ficheiro e conversão para dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_587876/385424208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ml13_ini_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://app.parlamento.pt/webutils/docs/doc.xml?path=6148523063446f764c324679626d56304c3239775a57356b595852684c3052685a47397a51574a6c636e52766379394a626d6c6a6157463061585a686379395953556c4a4a5449775447566e61584e7359585231636d45765357357059326c6864476c3259584e5953556c4a4c6e687462413d3d&fich=IniciativasXIII.xml&Inline=true'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ml13_ini_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml13_ini_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0ml14_ini_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    543\u001b[0m                                   '_open', req)\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1398\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jupyterbook/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "l13_ini_url = 'https://app.parlamento.pt/webutils/docs/doc.xml?path=6148523063446f764c324679626d56304c3239775a57356b595852684c3052685a47397a51574a6c636e52766379394a626d6c6a6157463061585a686379395953556c4a4a5449775447566e61584e7359585231636d45765357357059326c6864476c3259584e5953556c4a4c6e687462413d3d&fich=IniciativasXIII.xml&Inline=true'\n",
    "l13_ini_tree = ET.parse(urlopen(l13_ini_url))\n",
    "\n",
    "l14_ini_url = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x7fc89c252130>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l13_ini_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "## Iteract through the existing dict\n",
    "def party_from_votes (votes):\n",
    "    \"\"\"\n",
    "    Determines the position of a party based on the majority position by summing all the individual votes.\n",
    "    Argument is a dictionary returned by parse_voting()\n",
    "    Returns a dictionary with the majority position of each party\n",
    "    \"\"\"\n",
    "    party_vote = {}\n",
    "    for k, v in votes.items():\n",
    "        ## Erase the name of the MP and keep the party only\n",
    "        ## only when it's not from the \"Ninsc\" group - \n",
    "        ## these need to be differentiated by name\n",
    "        if re.match(\".*\\(Ninsc\\)\" , k) is None:\n",
    "            nk = re.sub(r\".*\\((.+?)\\).*\", r\"\\1\", k)\n",
    "        else:\n",
    "            nk = k\n",
    "        ## If it's the first entry for a key, create it\n",
    "        if nk not in party_vote:\n",
    "            party_vote[nk] = [0,0,0]\n",
    "        ## Add to a specific index in a list\n",
    "        if v == \"A Favor\":\n",
    "            party_vote[nk][0] += 1\n",
    "        elif v == \"Abstenção\":\n",
    "            party_vote[nk][1] += 1\n",
    "        elif v == \"Contra\":\n",
    "            party_vote[nk][2] += 1\n",
    "    for k,v in party_vote.items():\n",
    "        party_vote[k]=[\"A Favor\", \"Abstenção\", \"Contra\"][v.index(max(v))]\n",
    "    return party_vote\n",
    "\n",
    "def parse_voting(v_str):\n",
    "    \"\"\"Parses the voting details in a string and returns a dict.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    \n",
    "    v_str: a string with the description of the voting behaviour.\n",
    "    \"\"\"\n",
    "    ## Split by the HTML line break and put it in a dict\n",
    "    d = dict(x.split(':') for x in v_str.split('<BR>'))\n",
    "    ## Remove the HTML tags\n",
    "    for k, v in d.items():\n",
    "        ctext = BeautifulSoup(v, \"lxml\")\n",
    "        d[k] = ctext.get_text().strip().split(\",\")\n",
    "    ## Invert the dict to get a 1-to-1 mapping\n",
    "    ## and trim it\n",
    "    votes = {}\n",
    "    if len(v_str) < 1000:    # Naive approach but realistically speaking... works well enough.\n",
    "        for k, v in d.items():\n",
    "            for p in v:\n",
    "                if (p != ' ' and                                       # Bypass empty entries\n",
    "                    re.match(\"[0-9]+\", p.strip()) is None and           # Bypass quantified divergent voting patterns\n",
    "                    (re.match(\".*\\w +\\(.+\\)\", p.strip()) is None or     # Bypass individual votes...\n",
    "                     re.match(\".*\\(Ninsc\\)\" , p.strip()) is not None)): # ... except when coming from \"Ninsc\"\n",
    "                        #print(\"|\"+ p.strip() + \"|\" + \":\\t\" + k)\n",
    "                        votes[p.strip()] = k\n",
    "    else:  # This is a nominal vote since the size of the string is greater than 1000\n",
    "        for k, v in d.items():\n",
    "            for p in v:\n",
    "                if p != ' ':\n",
    "                    votes[p.strip()] = k\n",
    "        ## Call the auxiliary function to produce the party position based on the majority votes\n",
    "        votes = party_from_votes(votes)\n",
    "    return votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................6400\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "root = l13_ini_tree\n",
    "\n",
    "counter=0\n",
    "\n",
    "## We will build a dataframe from a list of dicts\n",
    "## Inspired by the approach of Chris Moffitt here https://pbpython.com/pandas-list-dict.html\n",
    "l13_init_list = []\n",
    "\n",
    "for voting in root.findall(\".//pt_gov_ar_objectos_VotacaoOut\"):\n",
    "    votep = voting.find('./detalhe')\n",
    "    if votep is not None:\n",
    "        init_dict = collections.OrderedDict()\n",
    "        counter +=1                 \n",
    "        init_dict['id'] = voting.find('id').text\n",
    "        ## Add the \"I\" for Type to mark this as coming from \"Iniciativas\"\n",
    "        init_dict['Tipo'] = \"I\"\n",
    "        for c in voting:\n",
    "            if c.tag == \"detalhe\":\n",
    "                for party, vote in parse_voting(c.text).items():\n",
    "                    init_dict[party] = vote \n",
    "            elif c.tag == \"descricao\":\n",
    "                    init_dict[c.tag] = c.text\n",
    "            elif c.tag == \"ausencias\":\n",
    "                    init_dict[c.tag] = c.find(\"string\").text\n",
    "            else:\n",
    "                    init_dict[c.tag] = c.text\n",
    "        l13_init_list.append(init_dict)\n",
    "    ## Provide progression feedback\n",
    "    print('.', end='')\n",
    "        \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Tipo', 'resultado', 'descricao', 'reuniao', 'tipoReuniao', 'PS',\n",
       "       'BE', 'CDS-PP', 'PCP', 'PEV', 'PAN', 'PSD', 'data', 'unanime',\n",
       "       'publicacao', 'ausencias', 'Paulo Trigo Pereira (Ninsc)', '2-PS',\n",
       "       '32-PS', '10-CDS-PP', '80-PSD', '25-PS', '1-CDS-PP', '15-PCP', '2-PEV',\n",
       "       '1-PAN', '43-PS', '18-BE', '8-CDS-PP', '12-PS', 'IL',\n",
       "       'Cristina Rodrigues (Ninsc)', 'CH', 'Joacine Katar Moreira (Ninsc)',\n",
       "       'L'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "l13_ini_df = pd.DataFrame(l13_init_list)\n",
    "#print(ini_df.shape)\n",
    "l13_ini_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy Livre voting record to new aggregate columns...\n",
    "l13_ini_df[\"L/JKM\"] = l13_ini_df[\"L\"]\n",
    "## ... and fill the NAs with JKM voting record.\n",
    "l13_ini_df[\"L/JKM\"] = l13_ini_df[\"L/JKM\"].fillna(l13_ini_df[\"Joacine Katar Moreira (Ninsc)\"])\n",
    "l13_ini_df[[\"descricao\",\"L\",\"Joacine Katar Moreira (Ninsc)\",\"L/JKM\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy PAN voting record to new aggregate columns...\n",
    "l13_ini_df[\"PAN/CR\"] = l13_ini_df[\"PAN\"]\n",
    "## ... and update/replace with CR voting where it exists\n",
    "l13_ini_df[\"PAN/CR\"].update(l13_ini_df[\"Cristina Rodrigues (Ninsc)\"])\n",
    "l13_ini_df[[\"descricao\",\"PAN\",\"Cristina Rodrigues (Ninsc)\",\"PAN/CR\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividades\n",
    "\n",
    "Não há detalhe das votações para as Actividades da XIII legislatura!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l13_act_url = 'https://app.parlamento.pt/webutils/docs/doc.xml?path=6148523063446f764c324679626d56304c3239775a57356b595852684c3052685a47397a51574a6c636e52766379394264476c32615752685a47567a4c31684a53556b6c4d6a424d5a57647063327868644856795953394264476c32615752685a47567a57456c4a535335346257773d&fich=AtividadesXIII.xml&Inline=true'\n",
    "l13_act_tree = ET.parse(urlopen(l13_act_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "root = l13_act_tree\n",
    "\n",
    "counter=0\n",
    "\n",
    "## We will build a dataframe from a list of dicts\n",
    "## Inspired by the approach of Chris Moffitt here https://pbpython.com/pandas-list-dict.html\n",
    "l13_act_list = []\n",
    "\n",
    "def get_toplevel_desc (vid, tree):\n",
    "    \"\"\"\n",
    "    Gets the top-level title from a voting id\n",
    "    \"\"\"\n",
    "    for c in tree.find(\".//pt_gov_ar_objectos_VotacaoOut/[id='\"+ vid +\"']/../..\"):\n",
    "        if c.tag == \"assunto\":\n",
    "            return c.text\n",
    "\n",
    "for voting in root.findall(\".//pt_gov_ar_objectos_VotacaoOut\"):\n",
    "    act_dict = collections.OrderedDict()\n",
    "    counter +=1\n",
    "    votep = voting.find('./detalhe')\n",
    "    if votep is not None:\n",
    "        print(\"x\")\n",
    "        act_dict['id'] = voting.find('id').text\n",
    "        ## Add the \"A\" for Type to mark this as coming from \"Iniciativas\"\n",
    "        act_dict['Tipo'] = \"A\"\n",
    "        for c in voting:\n",
    "            if c.tag == \"id\":\n",
    "                act_dict['descricao'] = get_toplevel_desc(c.text, act_tree)\n",
    "            if c.tag == \"detalhe\":\n",
    "                for party, vote in parse_voting(c.text).items():\n",
    "                    act_dict[party] = vote \n",
    "            elif c.tag == \"ausencias\":\n",
    "                    act_dict[c.tag] = c.find(\"string\").text\n",
    "            else:\n",
    "                    act_dict[c.tag] = c.text\n",
    "        l13_act_list.append(act_dict)\n",
    "    ## Provide progression feedback\n",
    "    print('.', end='')\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l13_act_df = pd.DataFrame(l13_act_list)\n",
    "#print(act_df.shape)\n",
    "\n",
    "l13_act_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy Livre voting record to new aggregate columns...\n",
    "act_df[\"L/JKM\"] = act_df[\"L\"]\n",
    "## ... and fill the NAs with JKM voting record.\n",
    "act_df[\"L/JKM\"] = act_df[\"L/JKM\"].fillna(act_df[\"Joacine Katar Moreira (Ninsc)\"])\n",
    "\n",
    "## Copy PAN voting record to new aggregate columns...\n",
    "act_df[\"PAN/CR\"] = act_df[\"PAN\"]\n",
    "## ... and update/replace with CR voting where it exists\n",
    "act_df[\"PAN/CR\"].update(act_df[\"Cristina Rodrigues (Ninsc)\"])\n",
    "#act_df[[\"descricao\",\"PAN\",\"Cristina Rodrigues (Ninsc)\",\"PAN/CR\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#votes = pd.concat([ini_df.drop([\"tipoReuniao\"],axis=1),act_df.drop([\"data\",\"publicacao\"],axis=1)], sort=True)\n",
    "l13_votes = l13_ini_df.drop([\"tipoReuniao\"],axis=1)\n",
    "l13_votes_hm = l13_votes[['BE', 'PCP', 'PEV', 'L/JKM', 'PS', 'PAN','PAN/CR','PSD','IL','CDS-PP', 'CH']]\n",
    "l13_votes=l13_votes[l13_votes['unanime'] != 'unanime']\n",
    "\n",
    "l13_votes_hm = l13_votes[['BE', 'PCP', 'PEV', 'L/JKM', 'PS', 'PAN','PAN/CR','PSD','IL','CDS-PP', 'CH']]\n",
    "l13_votes[\"data\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapa térmico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "l13_votes_hmn = l13_votes_hm.replace([\"A Favor\", \"Contra\", \"Abstenção\", \"Ausência\"], [1,-1,0,2]).fillna(0)\n",
    "\n",
    "voting_palette = [\"#FB6962\",\"#FCFC99\",\"#79DE79\", \"black\"]\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.heatmap(l13_votes_hmn,\n",
    "            square=False,\n",
    "            yticklabels = False,\n",
    "            cbar=False,\n",
    "            cmap=sns.color_palette(voting_palette),\n",
    "           )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quem vota com quem\n",
    "\n",
    "Com estes dados podemos tentar obter uma resposta mais clara do que o \"mapa térmico\" anterior nos apresenta como sendo semelhanças e diferenças no registo de votação.\n",
    "\n",
    "Uma das questões que se coloca (e normalmente coloca-se com maior ênfase sempre que há uma votação que é apontada como sendo \"atípica\", com base na percepção geral do que é o comportamente de voto habitual de cada partido) é saber \"quem vota com quem\". Estes dados podem ser obtidos através da identificação, para cada partido, da quantidade de votações onde cada outro votou da mesma forma e criação de uma tabela com os resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pv_list = []\n",
    "print(\"Total voting instances: \", l13_votes_hm.shape[0])\n",
    "\n",
    "## Not necessarily the most straightforard way (check .crosstab or .pivot_table, possibly with pandas.melt and/or groupby)\n",
    "## but follows the same approach as before in using a list of dicts\n",
    "for party in l13_votes_hm.columns:\n",
    "    pv_dict = collections.OrderedDict()\n",
    "    for column in l13_votes_hmn:\n",
    "        pv_dict[column]=l13_votes_hmn[l13_votes_hmn[party] == l13_votes_hmn[column]].shape[0]\n",
    "    pv_list.append(pv_dict)\n",
    "\n",
    "l13_pv = pd.DataFrame(pv_list,index=l13_votes_hm.columns)\n",
    "l13_pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sns.heatmap(\n",
    "    l13_pv,\n",
    "    cmap=sns.color_palette(\"mako_r\"),\n",
    "    linewidth=1,\n",
    "    annot = True,\n",
    "    square =True,\n",
    "    fmt=\"d\",\n",
    "    cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Portuguese Parliament 13th Legislature, identical voting count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de distância\n",
    "\n",
    "Com base nos histórico de votações de cada partido produzimos uma matriz de distâncias entre eles; uma matriz de distâncias é uma matriz quadradra $n\\times n$ (onde _n_ é o número de partidos) e onde a distância entre _p_ e _q_ é o valor de $ d_{pq} $.\n",
    "\n",
    "$ \n",
    "\\begin{equation}\n",
    "D= \\begin{bmatrix} d_{11} & d_{12} & \\cdots & d_{1 n} \\\\  d_{21} & d_{22} & \\cdots & d_{2 n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ d_{31} & d_{32} & \\cdots & d_{n n}   \\end{bmatrix}_{\\ n\\times n}  \n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "\n",
    "A distância é obtida através da comparação de todas as observações de cada par usando uma determinada métrica de distância, sendo a distância euclideana bastante comum em termos gerais e também dentro de estudos sobre o mesmo domínio temático _(Krilavičius and Žilinskas 2008)_: cada elemento da matriz representa $ d\\left( p,q\\right)   = \\sqrt {\\sum _{i=1}^{n}  \\left( q_{i}-p_{i}\\right)^2 }$, equivalente, para dois pontos $P,Q $ , à mais genérica distância de Minkowski   $ D\\left(P,Q\\right)=\\left(\\sum _{i=1}^{n}|x_{i}-y_{i}|^{p}\\right)^{\\frac {1}{p}} $ para $ p = 1$, mas note-se que a diagonal da matrix irá representar a distância entre um partido e ele próprio, logo $ d_{11} = d_{22} = \\dots = d_{nn} = 0 $.\n",
    "\n",
    "Na secção  [Distâncias e matrizes](Distâncias_e_matrizes) colocámos uma discussão mais detalhada (mas passo-a-passo e destinada a quem não tenha necessariamente presente a matemática utilizada) sobre distâncias, _clustering_ e como são calculdadas, para quem tenha interesse numa compreensão mais quantitativa da matéria.\n",
    "\n",
    "A conversão de votos em representações númericas pode ser feita de várias formas _(Hix, Noury, and Roland 2006)_; adoptamos a abordagem de Krilavičius & Žilinskas (2008) no já citado  trabalho relativo às votações no parlamento lituano por nos parecer apropriada à realidade portuguesa:\n",
    "\n",
    "* A favor: 1\n",
    "* Contra: -1\n",
    "* Abstenção: 0\n",
    "* Ausência: 0\n",
    "\n",
    "Este ponto é (mais um) dos que de forma relativamente opaca - pois raramente os detalhes têm a mesma projecção que os resultado finais - podem influenciar os resultados; cremos que em particular a equiparação entre _abstenção_ e _ausência_ merece alguma reflexão: considerámos que uma ausência em determinada votação tem um peso equivalente à abstenção, embora uma de forma passiva e outra activa.\n",
    "\n",
    "Para obtermos a matriz de distância usamos a função `pdist` e construímos um _dataframe_ que é uma matriz simétrica das distâncias entre os partidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform\n",
    "from scipy.spatial.distance import pdist\n",
    "import scipy.spatial as sp, scipy.cluster.hierarchy as hc\n",
    "from itables import show\n",
    "\n",
    "l13_votes_hmn = l13_votes_hm.replace([\"A Favor\", \"Contra\", \"Abstenção\", \"Ausência\"], [1,-1,0,0]).fillna(0)\n",
    "\n",
    "## Transpose the dataframe used for the heatmap\n",
    "l13_votes_t = l13_votes_hmn.transpose()\n",
    "\n",
    "## Determine the Eucledian pairwise distance\n",
    "## (\"euclidean\" is actually the default option)\n",
    "l13_pwdist = pdist(l13_votes_t, metric='euclidean')\n",
    "\n",
    "## Create a square dataframe with the pairwise distances: the distance matrix\n",
    "l13_distmat = pd.DataFrame(\n",
    "    squareform(l13_pwdist), # pass a symmetric distance matrix\n",
    "    columns = l13_votes_t.index,\n",
    "    index = l13_votes_t.index\n",
    ")\n",
    "#show(distmat, scrollY=\"200px\", scrollCollapse=True, paging=False)\n",
    "\n",
    "## Normalise by scaling between 0-1, using dataframe max value to keep the symmetry.\n",
    "## This is essentially a cosmetic step to \n",
    "#distmat=((distmat-distmat.min().min())/(distmat.max().max()-distmat.min().min()))*1\n",
    "l13_distmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the heatmap of the distance matrix\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sns.heatmap(\n",
    "    l13_distmat,\n",
    "    cmap=sns.color_palette(\"Reds_r\"),\n",
    "    linewidth=1,\n",
    "    annot = True,\n",
    "    square =True,\n",
    "    cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Portuguese Parliament 13th Legislature, Distance Matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform hierarchical linkage on the distance matrix using Ward's method.\n",
    "l13_distmat_link = hc.linkage(l13_pwdist, method=\"ward\", optimal_ordering=True )\n",
    "\n",
    "sns.clustermap(\n",
    "    l13_distmat,\n",
    "    annot = True,\n",
    "    cmap=sns.color_palette(\"Reds_r\"),\n",
    "    linewidth=1,\n",
    "    #standard_scale=1,\n",
    "    row_linkage=l13_distmat_link,\n",
    "    col_linkage=l13_distmat_link,\n",
    "    figsize=(8,8)).fig.suptitle('Portuguese Parliament 13th Legislature, Clustermap')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "dendrogram(l13_distmat_link, labels=l13_votes_hmn.columns)\n",
    "\n",
    "plt.title(\"Portuguese Parliament 14th Legislature, Dendogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Clustering_ de observações: DBSCAN e _Spectrum Scaling_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "l13_distmat_mm=((l13_distmat-l13_distmat.min().min())/(l13_distmat.max().max()-l13_distmat.min().min()))*1\n",
    "pd.DataFrame(l13_distmat_mm, l13_distmat.index, l13_distmat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l13_affinmat_mm = pd.DataFrame(1-l13_distmat_mm, l13_distmat.index, l13_distmat.columns)\n",
    "l13_affinmat_mm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "\n",
    "## Make the top triangle\n",
    "mask = np.triu(np.ones_like(l13_affinmat_mm, dtype=bool))\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot()\n",
    "plt.title('Portuguese Parliament 13th Legislature, Affinity Matrix')\n",
    "\n",
    "## Display the heatmap of the affinity matrix, masking the top triangle\n",
    "\n",
    "sns.heatmap(\n",
    "    l13_affinmat_mm,\n",
    "    cmap=sns.color_palette(\"Greens\"),\n",
    "    linewidth=1,\n",
    "    annot = False,\n",
    "    square =True,\n",
    "    cbar_kws={\"shrink\": .8},\n",
    "    mask=mask,linewidths=.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan_labels = DBSCAN(eps=1.1).fit(l13_affinmat_mm)\n",
    "dbscan_labels.labels_\n",
    "dbscan_dict = dict(zip(l13_distmat_mm,dbscan_labels.labels_))\n",
    "dbscan_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "sc = SpectralClustering(4, affinity=\"precomputed\",random_state=2020).fit_predict(l13_affinmat_mm)\n",
    "sc_dict = dict(zip(l13_distmat,sc))\n",
    "\n",
    "print(sc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Multidimensional scaling_ \n",
    "\n",
    "Até agora temos conseguido extrair informação interessante dos dados de votação:\n",
    "\n",
    "1. O mapa térmico de votação permite-nos uma primeira visão do comportamente de todos os partidos. \n",
    "2. A matriz de distâncias fornece-nos uma forma de comparar as distâncias entre os diferentes partidos através de um mapa térmico.\n",
    "3. O dendograma identifica de forma hierárquica agrupamentos.\n",
    "4. Através de DBSCAN e _Spectrum Clustering_ identificamos \"blocos\" com base na matriz de afinidade.\n",
    "\n",
    "Não temos ainda uma forma de visualizar a distância relativa de cada partido em relação aos outros com base nas distâncias/semelhanças: temos algo próximo com base no dendograma mas existem outras formas de visualização interessantes.\n",
    "\n",
    "Uma das formas é o _multidimensional scaling_ que permite visualizar a distância ao projectar em 2 ou 3 dimensões (também conhecidas como _dimensões visualizavies_) conjuntos multidimensionais, mantendo a distância relativa _(“Graphical Representation of Proximity Measures for Multidimensional Data « The Mathematica Journal” 2020)_.\n",
    "\n",
    "Como é habitual temos em Python, através da biblioteca `scikit-learn` (que já usámos para DBSCAN e _Spectrum Clustering_), uma implementação que podemos usar sem grande dificuldade _(“2.2. Manifold Learning — Scikit-Learn 0.23.2 Documentation” 2020)_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed',random_state=2020, n_init=100, max_iter=1000)\n",
    "\n",
    "## We use the normalised distance matrix but results would\n",
    "## be similar with the original one, just with a different scale/axis\n",
    "results = mds.fit(l13_distmat_mm.values)\n",
    "coords = results.embedding_\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graphic options\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "plt.title('Portuguese Parliament Voting Records Analysis, 13th Legislature', fontsize=14)\n",
    "\n",
    "for label, x, y in zip(l13_distmat_mm.columns, coords[:, 0], coords[:, 1]):\n",
    "    ax.scatter(x, y, s=250)\n",
    "    ax.axis('equal')\n",
    "    ax.annotate(label,xy = (x-0.02, y+0.025))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "import random\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "fig.suptitle('Portuguese Parliament Voting Records Analysis, 13th Legislature', fontsize=14)\n",
    "ax.set_title('MDS with DBSCAN clusters (2D)')\n",
    "\n",
    "for label, x, y in zip(l13_distmat_mm.columns, coords[:, 0], coords[:, 1]):\n",
    "    ax.scatter(x, y, c = \"C\"+str(1+dbscan_dict[label]), s=250)\n",
    "    ax.axis('equal')\n",
    "    ax.annotate(label,xy = (x-0.02, y+0.025))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "import random\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "fig.suptitle('Portuguese Parliament Voting Records Analysis, 14th Legislature', fontsize=14)\n",
    "ax.set_title('MDS with Spectrum Scaling clusters (2D)')\n",
    "\n",
    "\n",
    "for label, x, y in zip(l13_distmat_mm.columns, coords[:, 0], coords[:, 1]):\n",
    "    ax.scatter(x, y, c = \"C\"+str(sc_dict[label]), s=250)\n",
    "    ax.axis('equal')\n",
    "    ax.annotate(label,xy = (x-0.02, y+0.025))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From https://stackoverflow.com/questions/10374930/matplotlib-annotating-a-3d-scatter-plot\n",
    "\n",
    "from mpl_toolkits.mplot3d.proj3d import proj_transform\n",
    "from matplotlib.text import Annotation\n",
    "\n",
    "class Annotation3D(Annotation):\n",
    "    '''Annotate the point xyz with text s'''\n",
    "\n",
    "    def __init__(self, s, xyz, *args, **kwargs):\n",
    "        Annotation.__init__(self,s, xy=(0,0), *args, **kwargs)\n",
    "        self._verts3d = xyz        \n",
    "\n",
    "    def draw(self, renderer):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
    "        self.xy=(xs,ys)\n",
    "        Annotation.draw(self, renderer)\n",
    "        \n",
    "def annotate3D(ax, s, *args, **kwargs):\n",
    "    '''add anotation text s to to Axes3d ax'''\n",
    "\n",
    "    tag = Annotation3D(s, *args, **kwargs)\n",
    "    ax.add_artist(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "import mpl_toolkits.mplot3d\n",
    "import random\n",
    "\n",
    "mds = MDS(n_components=3, dissimilarity='precomputed',random_state=1234, n_init=100, max_iter=1000)\n",
    "results = mds.fit(l13_distmat.values)\n",
    "parties = l13_distmat.columns\n",
    "coords = results.embedding_\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "fig.suptitle('Portuguese Parliament Voting Records Analysis, 13th Legislature', fontsize=14)\n",
    "ax.set_title('MDS with Spectrum Scaling clusters (3D)')\n",
    "\n",
    "for label, x, y, z in zip(parties, coords[:, 0], coords[:, 1], coords[:, 2]):\n",
    "    #print(label,pmds_colors[label])\n",
    "    ax.scatter(x, y, z, c=\"C\"+str(sc_dict[label]),s=250)\n",
    "    annotate3D(ax, s=str(label), xyz=[x,y,z], fontsize=10, xytext=(-3,3),\n",
    "               textcoords='offset points', ha='right',va='bottom')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}